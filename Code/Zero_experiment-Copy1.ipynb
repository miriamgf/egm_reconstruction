{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627988e9",
   "metadata": {},
   "source": [
    "# Experiment with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f580a87",
   "metadata": {},
   "source": [
    "## Set paths, additional functions and import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8dbd0c",
   "metadata": {},
   "source": [
    "**Set paths and functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07da78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = '../Logs/'\n",
    "data_dir = '../Data'\n",
    "figs_dir = 'Figs/'\n",
    "models_dir = '../Models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b9b67",
   "metadata": {},
   "source": [
    "**Set functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e1e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard logs name generator\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566103fd",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a11197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models, layers\n",
    "import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from itertools import product\n",
    "from tools import *\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model\n",
    "import pickle\n",
    "from generators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a109bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import sensitivity_specificity_support\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f761b582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:33:13.579261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-20 11:33:13.731358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-20 11:33:13.731613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f419befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e2c86",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2476d90",
   "metadata": {},
   "source": [
    "* X = 64 BSPs\n",
    "* Y = labels (0-6) (Labels 6-7 are unified)\n",
    "* Y_model = identifier of the AF model (1 to 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb263af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LA_LIPV_150119', 'LA_LSPV_150113', 'LA_LSPV_150203', 'LA_PLAW_140612', 'LA_PLAW_140711_arm', 'LA_RIPV_150121', 'LA_RSPV_150113', 'LA_RSPV_CAF_150115', 'RA_RAA_141216', 'RA_RAA_141230', 'RA_RAFW_140807', 'RA_RAFW_SAF_140730', 'Sinusal_150629', 'TwoRotors_181219']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3961/1868821791.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;31m#1: Rotor/no rotor ; 2: RA/LA/No rotor (2 classes) ; 3: 7 regions (3 classes) + no rotor (8 classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_1channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1channelTensor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsampling\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_sub\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "\n",
    "n_classes = 3 #1: Rotor/no rotor ; 2: RA/LA/No rotor (2 classes) ; 3: 7 regions (3 classes) + no rotor (8 classes)\n",
    "\n",
    "X_1channel,Y,Y_model = load_data(data_type='1channelTensor', n_classes=n_classes, subsampling= True, fs_sub=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d56653",
   "metadata": {},
   "source": [
    "n_batches_train,n_batches_test,train_1gen,test_1gen, train_sigs=generator_batches_autoencoder(X_1channel,Y,Y_model,data_type='1channelTensor',val_percentage=0.2,test_percentage=0.2,input_size=500,SNR=20,val=False, shuffle_batches_train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94893c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_model)\n",
    "len(Y_model)\n",
    "count=0\n",
    "for i in Y_model:\n",
    "    if i==1:\n",
    "        count+=1\n",
    "print(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03accbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_1channel.shape)\n",
    "\n",
    "def define_image(time_instant, Tensor):\n",
    "    image=Tensor[time_instant,: ,: ]\n",
    "    return image\n",
    "def define_frames(Tensor):\n",
    "    ims = []\n",
    "    for i in range(200):\n",
    "        ims.append([Tensor[i, :, :]])\n",
    "    return ims\n",
    "    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bce586",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "image=define_image(5,X_1channel )\n",
    "plt.imshow(image, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeb4bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(1,10):\n",
    "    image=define_image(i, X_1channel)\n",
    "    plt.subplot(10, 1, i)\n",
    "    plt.imshow(image) #map='jet')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf09a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(X_1channel)*0.7)+1+int(len(X_1channel)*0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import reshape\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_train= X_1channel[0:int(len(X_1channel)*0.7), :]\n",
    "x_test= X_1channel[int(len(X_1channel)*0.7)+1:int(len(X_1channel)*0.7)+1+int(len(X_1channel)*0.25), :, :]\n",
    "x_val= X_1channel[int(len(X_1channel)*0.7)+1+int(len(X_1channel)*0.25):-1, :, :]\n",
    "x_train_or, x_test_or, x_val_or=x_train, x_test, x_val\n",
    "\n",
    "#Standardization\n",
    "scalers = {}\n",
    "for i in range(x_train.shape[1]):\n",
    "    scalers[i] = StandardScaler()\n",
    "    x_train[:, i, :] = scalers[i].fit_transform(x_train[:, i, :]) \n",
    "\n",
    "for i in range(x_test.shape[1]):\n",
    "    x_test[:, i, :] = scalers[i].transform(x_test[:, i, :]) \n",
    "    \n",
    "for i in range(x_val.shape[1]):\n",
    "    x_val[:, i, :] = scalers[i].transform(x_val[:, i, :]) \n",
    "x_train_st=x_train\n",
    "\n",
    "#Reshape for interpolation\n",
    "print(x_train.shape, x_test.shape, x_val.shape) \n",
    "x_train = reshape(x_train, (len(x_train), 6, 16,1)) \n",
    "x_test = reshape(x_test, (len(x_test), 6, 16,1))\n",
    "x_val = reshape(x_val, (len(x_val), 6, 16,1))\n",
    "print(x_train.shape, x_test.shape, x_val.shape) \n",
    "\n",
    "#Interpolation\n",
    "x_train = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x_train)\n",
    "x_test = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x_test)\n",
    "x_val = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x_val)\n",
    "print(x_train.shape, x_test.shape) \n",
    "\n",
    "#Plot\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "image=define_image(1000,x_train_or)\n",
    "plt.imshow(image, cmap='jet')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "image=define_image(1000,x_train_st )\n",
    "plt.imshow(image, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf5029",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_mode = '2D CNN'\n",
    "n_batch=500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6bd9f7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "if autoencoder_mode == '2D CNN':\n",
    "    encoder = models.Sequential()\n",
    "    #encoder.add(layers.Input(shape=( 6, 16,1)))\n",
    "    encoder.add(layers.Conv2D(64, (2, 2), strides=1, padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
    "    encoder.add(layers.MaxPooling2D((2, 2)))\n",
    "    encoder.add(layers.Dropout(0.2))\n",
    "    encoder.add(layers.Conv2D(12, (2, 2), strides=1, padding='same', activation='relu'))\n",
    "    encoder.add(layers.MaxPooling2D((1, 2)))\n",
    "    encoder.summary()\n",
    "    decoder = models.Sequential()\n",
    "    decoder.add(layers.Conv2D(12, (2,2), strides=1, padding='same', activation='relu', input_shape=encoder.output.shape[1:]))\n",
    "    decoder.add(layers.UpSampling2D((1, 2)))\n",
    "    decoder.add(layers.Dropout(0.2))\n",
    "    decoder.add(layers.Conv2D(64, (2,2), strides=1, padding='same', activation='relu'))\n",
    "    decoder.add(layers.UpSampling2D((2, 2)))\n",
    "    decoder.add(layers.Conv2D(1, (2,2), strides=1, padding='same', activation='linear'))\n",
    "    decoder.summary()\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.Sequential()\n",
    "#encoder.add(layers.Input(shape=( 6, 16,1)))\n",
    "encoder.add(layers.Conv2D(64, (2, 2), strides=1, padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
    "encoder.add(layers.MaxPooling2D((2, 2)))\n",
    "encoder.add(layers.Dropout(0.2))\n",
    "encoder.add(layers.Conv2D(12, (2, 2), strides=1, padding='same', activation='relu'))\n",
    "encoder.add(layers.MaxPooling2D((2, 2)))\n",
    "encoder.add(layers.Conv2D(12, (2, 2), strides=1, padding='same', activation='relu'))\n",
    "encoder.add(layers.MaxPooling2D((3, 2)))\n",
    "encoder.summary()\n",
    "decoder = models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.add(layers.Conv2D(12, (2,2), strides=1, padding='same', activation='relu', input_shape=encoder.output.shape[1:]))\n",
    "decoder.add(layers.UpSampling2D((3, 2)))\n",
    "decoder.add(layers.Conv2D(12, (2,2), strides=1, padding='same', activation='relu', input_shape=encoder.output.shape[1:]))\n",
    "decoder.add(layers.UpSampling2D((2, 2)))\n",
    "decoder.add(layers.Dropout(0.2))\n",
    "decoder.add(layers.Conv2D(64, (2,2), strides=1, padding='same', activation='relu'))\n",
    "decoder.add(layers.UpSampling2D((2, 2)))\n",
    "decoder.add(layers.Conv2D(1, (2,2), strides=1, padding='same', activation='linear'))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ead86",
   "metadata": {},
   "source": [
    "elif autoencoder_mode == 'ConvLSTM':\n",
    "    encoder = models.Sequential()\n",
    "    #encoder.add(layers.Input(shape=(n_batch, 6, 16,1)))\n",
    "    encoder.add(layers.ConvLSTM2D(64, (2, 2), strides=1, padding='same', activation='relu',input_shape=(6, 16,1), return_sequences=True))\n",
    "    encoder.add(layers.MaxPooling2D((2, 2)))\n",
    "    encoder.add(layers.Dropout(0.2))\n",
    "    #encoder.add(Flatten())\n",
    "    encoder.add(layers.Conv2D(12, (2, 2), strides=1, padding='same', activation='relu', return_sequences=True))\n",
    "    encoder.add(layers.MaxPooling2D((1, 2)))\n",
    "    encoder.summary()\n",
    "    decoder = models.Sequential()\n",
    "    decoder.add(layers.Conv2D(12, (2,2), strides=1, padding='same', activation='relu', input_shape=encoder.output.shape[1:], return_sequences=True))\n",
    "    decoder.add(layers.UpSampling2D((1, 2)))\n",
    "    decoder.add(layers.Dropout(0.2))\n",
    "    decoder.add(layers.Conv2D(64, (2,2), strides=1, padding='same', activation='relu', return_sequences=True))\n",
    "    decoder.add(layers.UpSampling2D((2, 2)))\n",
    "    decoder.add(layers.Conv2D(1, (2,2), strides=1, padding='same', activation='linear', return_sequences=True))\n",
    "    decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe7351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_autoencoder = Model(inputs=encoder.input, outputs=decoder(encoder.outputs))\n",
    "conv_autoencoder.compile(optimizer='adam', loss=losses.mean_squared_error)\n",
    "history = conv_autoencoder.fit(x_train, x_train, batch_size=n_batch, epochs=20, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807db638",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = conv_autoencoder.predict(x_val)\n",
    "print(decoded_imgs.shape, x_val.shape)\n",
    "decoded_imgs = reshape(decoded_imgs, (len(decoded_imgs), decoded_imgs.shape[1],  decoded_imgs.shape[2]))\n",
    "x_val = reshape(x_val, (len(x_val),x_val.shape[1],  x_val.shape[2])) \n",
    "print(decoded_imgs.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747a1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad908d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_instant= 14000\n",
    "\n",
    "plt.figure(figsize=(5,5), layout='tight')\n",
    "plt.subplot(3,1,1)\n",
    "image1=define_image(time_instant,x_val )\n",
    "min_val, max_val = np.amin(image1), np.amax(image1)\n",
    "plt.imshow(image1, vmin=min_val, vmax=max_val)#, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.title('Original')\n",
    "plt.subplot(3,1,2)\n",
    "image2=define_image(time_instant,decoded_imgs)\n",
    "plt.imshow(image2, vmin=min_val, vmax=max_val) #, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.title('Reconstructed')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(image2-image1, vmin=min_val, vmax=max_val)\n",
    "plt.title('Error (Reconstructed-Original)')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c65b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_val[0:1000, 1, 1], label=('Input'))\n",
    "plt.plot(decoded_imgs[0:1000, 1, 1], label=('Reconstruction'))\n",
    "plt.fill_between(np.arange(1000), decoded_imgs[0:1000, 1, 1],x_val[0:1000, 1, 1], color='lightgreen')\n",
    "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5246d0d9",
   "metadata": {},
   "source": [
    "# Latent Space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector = encoder.predict(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ddd914",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a55ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
